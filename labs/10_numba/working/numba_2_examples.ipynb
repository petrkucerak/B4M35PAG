{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install numba"
      ],
      "metadata": {
        "id": "j7b8epWRRIm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "AUTOMATIC PARALLELIZATION EXAMPLE:"
      ],
      "metadata": {
        "id": "PGDSWvSAIOb8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numba import njit, prange\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "\n",
        "# Function without parallelization\n",
        "def no_parallelization_example(A):\n",
        "    s = 0\n",
        "    for i in range(A.shape[0]):\n",
        "        s += A[i]\n",
        "    return s\n",
        "\n",
        "# Function with explicit prange for manual parallelization\n",
        "@njit(parallel=True)\n",
        "def manual_parallelization_example(A):\n",
        "    s = 0\n",
        "    for i in prange(A.shape[0]):\n",
        "        s += A[i]\n",
        "    return s\n",
        "\n",
        "# Function without explicit prange, allowing automatic parallelization\n",
        "@njit\n",
        "def automatic_parallelization_example(A):\n",
        "    s = 0\n",
        "    for i in range(A.shape[0]):\n",
        "        s += A[i]\n",
        "    return s\n",
        "\n",
        "\n",
        "# Create a 1D array with random values\n",
        "n = 20000000\n",
        "A = np.random.rand(n)\n",
        "\n",
        "# Measure the execution time\n",
        "start_time = time.time()\n",
        "result_auto = automatic_parallelization_example(A)\n",
        "auto_parallel_time = round(time.time() - start_time, 3)\n",
        "\n",
        "start_time = time.time()\n",
        "result_manual = manual_parallelization_example(A)\n",
        "manual_parallel_time = round(time.time() - start_time, 3)\n",
        "\n",
        "start_time = time.time()\n",
        "result_no_parallel = no_parallelization_example(A)\n",
        "no_parallel_time = round(time.time() - start_time, 3)\n",
        "\n",
        "# Print timing information\n",
        "print(\"No parallelization:\", no_parallel_time, \"sec\")\n",
        "print(\"Explicit parallelization:\", manual_parallel_time, \"sec\")\n",
        "print(\"Automatic parallelization:\", auto_parallel_time, \"sec\")"
      ],
      "metadata": {
        "id": "7G9VL1sWUFLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RACE CONDITION:"
      ],
      "metadata": {
        "id": "rS2CYZLn12I2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numba import njit, prange\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "@njit(parallel=True)\n",
        "def race_condition(x):\n",
        "    \"\"\"\n",
        "    Demonstrates a race condition by accumulating into the entire array `y`\n",
        "    from different parallel iterations of the loop.\n",
        "    \"\"\"\n",
        "    n = x.shape[0]\n",
        "    y = np.zeros(2)\n",
        "    for i in prange(n):\n",
        "        y[:] += x[i]\n",
        "\n",
        "    # Print the result after the parallel section\n",
        "    print(\"Result with race condition:\", y)\n",
        "\n",
        "\n",
        "@njit(parallel=True)\n",
        "def correct_version(x):\n",
        "    \"\"\"\n",
        "    Demonstrates correct parallel accumulation into the entire array `y`.\n",
        "    \"\"\"\n",
        "    n = x.shape[0]\n",
        "    y = np.zeros(2)\n",
        "    for i in prange(n):\n",
        "        y += x[i]\n",
        "\n",
        "    # Print the result after the parallel section\n",
        "    print(\"Result without race condition:\", y)\n",
        "\n",
        "# Example usage:\n",
        "x = np.ones(1000000)\n",
        "race_condition(x)\n",
        "correct_version(x)"
      ],
      "metadata": {
        "id": "t5jjBzaj14dI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SCHEDULING OF TASKS:"
      ],
      "metadata": {
        "id": "qSWms3-sIn5z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numba import njit, prange, set_parallel_chunksize, get_parallel_chunksize\n",
        "\n",
        "@njit(parallel=True)\n",
        "def chunk_size_exploration(n):\n",
        "    acc = 0\n",
        "    print(f\"Chunk size before parallel region: {get_parallel_chunksize()}\")\n",
        "    for i in prange(n):\n",
        "        if i == 0:\n",
        "            print(f\"Chunk size inside parallel region: {get_parallel_chunksize()}\")\n",
        "        acc += i\n",
        "    print(f\"Chunk size after parallel region: {get_parallel_chunksize()}\")\n",
        "    return acc\n",
        "\n",
        "n = 4\n",
        "result = set_parallel_chunksize(n)\n",
        "result = chunk_size_exploration(n)"
      ],
      "metadata": {
        "id": "p_CRl1ZvK61P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PERFORM PARALLEL DIAGNOSTIC:"
      ],
      "metadata": {
        "id": "otnMV9YALqUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@njit(parallel=True)\n",
        "def test(x):\n",
        "    n = x.shape[0]\n",
        "    a = np.sin(x)\n",
        "    b = np.cos(a * a)\n",
        "    acc = 0\n",
        "    for i in prange(n - 2):\n",
        "        for j in prange(n - 1):\n",
        "            acc += b[i] + b[j + 1]\n",
        "    return acc\n",
        "\n",
        "test(np.arange(10))\n",
        "\n",
        "test.parallel_diagnostics(level=4)"
      ],
      "metadata": {
        "id": "XVBb_zh_LpLK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "caf9ad54-4ad2-435a-cd6b-36011c2ba6cf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            "================================================================================\n",
            " Parallel Accelerator Optimizing:  Function test, <ipython-input-5-fb83a01b854e>\n",
            " (1)  \n",
            "================================================================================\n",
            "\n",
            "\n",
            "Parallel loop listing for  Function test, <ipython-input-5-fb83a01b854e> (1) \n",
            "--------------------------------------|loop #ID\n",
            "@njit(parallel=True)                  | \n",
            "def test(x):                          | \n",
            "    n = x.shape[0]                    | \n",
            "    a = np.sin(x)---------------------| #7\n",
            "    b = np.cos(a * a)-----------------| #8\n",
            "    acc = 0                           | \n",
            "    for i in prange(n - 2):-----------| #10\n",
            "        for j in prange(n - 1):-------| #9\n",
            "            acc += b[i] + b[j + 1]    | \n",
            "    return acc                        | \n",
            "--------------------------------- Fusing loops ---------------------------------\n",
            "Attempting fusion of parallel loops (combines loops with similar properties)...\n",
            "  Trying to fuse loops #7 and #8:\n",
            "    - fusion succeeded: parallel for-loop #8 is fused into for-loop #7.\n",
            "  Trying to fuse loops #7 and #10:\n",
            "    - fusion failed: loop dimension mismatched in axis 0. slice(0, x_size0.237, \n",
            "1) != slice(0, $46binary_subtract.18, 1)\n",
            "----------------------------- Before Optimisation ------------------------------\n",
            "Parallel region 0:\n",
            "+--7 (parallel)\n",
            "+--8 (parallel)\n",
            "\n",
            "\n",
            "Parallel region 1:\n",
            "+--10 (parallel)\n",
            "   +--9 (parallel)\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "------------------------------ After Optimisation ------------------------------\n",
            "Parallel region 0:\n",
            "+--7 (parallel, fused with loop(s): 8)\n",
            "\n",
            "\n",
            "Parallel region 1:\n",
            "+--10 (parallel)\n",
            "   +--9 (serial)\n",
            "\n",
            "\n",
            " \n",
            "Parallel region 0 (loop #7) had 1 loop(s) fused.\n",
            " \n",
            "Parallel region 1 (loop #10) had 0 loop(s) fused and 1 loop(s) serialized as \n",
            "part of the larger parallel loop (#10).\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            " \n",
            "---------------------------Loop invariant code motion---------------------------\n",
            "Allocation hoisting:\n",
            "No allocation hoisting found\n",
            "\n",
            "Instruction hoisting:\n",
            "loop #7:\n",
            "  Failed to hoist the following:\n",
            "    dependency: $arg_out_var.246 = getitem(value=x, index=$parfor__index_241.341, fn=<built-in function getitem>)\n",
            "    dependency: $14load_method.5.247 = getattr(value=$push_global_to_block.326, attr=sin)\n",
            "    dependency: $expr_out_var.245 = call $14load_method.5.247($arg_out_var.246, func=$14load_method.5.247, args=[Var($arg_out_var.246, <ipython-input-5-fb83a01b854e>:4)], kws=(), vararg=None, varkwarg=None, target=None)\n",
            "    dependency: $arg_out_var.253 = $expr_out_var.245 * $expr_out_var.245\n",
            "    dependency: $24load_method.9.256 = getattr(value=$push_global_to_block.327, attr=cos)\n",
            "    dependency: $expr_out_var.252 = call $24load_method.9.256($arg_out_var.253, func=$24load_method.9.256, args=[Var($arg_out_var.253, <ipython-input-5-fb83a01b854e>:5)], kws=(), vararg=None, varkwarg=None, target=None)\n",
            "loop #10:\n",
            "  Has the following hoisted:\n",
            "    $const60.4 = const(int, 1)\n",
            "    $62binary_subtract.5 = n - $const60.4\n",
            "  Failed to hoist the following:\n",
            "    dependency: acc_3 = acc.2\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "REFERENCES: https://numba.readthedocs.io/en/stable/user/parallel.html"
      ],
      "metadata": {
        "id": "HPotRBcrL76Q"
      }
    }
  ]
}